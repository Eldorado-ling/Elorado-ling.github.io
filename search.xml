<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>wx公众号-文章爬取</title>
      <link href="/2025/02/21/wx%E5%85%AC%E4%BC%97%E5%8F%B7-%E6%96%87%E7%AB%A0%E7%88%AC%E5%8F%96/"/>
      <url>/2025/02/21/wx%E5%85%AC%E4%BC%97%E5%8F%B7-%E6%96%87%E7%AB%A0%E7%88%AC%E5%8F%96/</url>
      
        <content type="html"><![CDATA[<h1 id="微信公众号图片爬取程序开发指南"><a href="#微信公众号图片爬取程序开发指南" class="headerlink" title="微信公众号图片爬取程序开发指南"></a>微信公众号图片爬取程序开发指南</h1><h2 id="一、技术选型对比"><a href="#一、技术选型对比" class="headerlink" title="一、技术选型对比"></a>一、技术选型对比</h2><table><thead><tr><th>方案</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>Requests+BeautifulSoup</td><td>轻量快速</td><td>无法处理动态加载内容</td></tr><tr><td>纯接口</td><td>稳定可靠</td><td></td></tr><tr><td>mitmdump抓包</td><td>可获取加密数据流</td><td>配置复杂</td></tr></tbody></table><hr><h2 id="二、基础版实现（静态页面）"><a href="#二、基础版实现（静态页面）" class="headerlink" title="二、基础版实现（静态页面）"></a>二、基础版实现（静态页面）</h2><h3 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1. 环境准备"></a>1. 环境准备</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install requests beautifulsoup4</span><br></pre></td></tr></table></figure><h3 id="2-核心代码"><a href="#2-核心代码" class="headerlink" title="2. 核心代码"></a>2. 核心代码</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests </span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup </span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">download_images</span>(<span class="params">url, save_dir=<span class="string">&#x27;wx_images&#x27;</span></span>):</span><br><span class="line">    <span class="comment"># 创建存储目录 </span></span><br><span class="line">    os.makedirs(save_dir,  exist_ok=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 发送请求 </span></span><br><span class="line">    headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36&#x27;</span>&#125;</span><br><span class="line">    response = requests.get(url,  headers=headers)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 解析图片链接 </span></span><br><span class="line">    soup = BeautifulSoup(response.text,  <span class="string">&#x27;html.parser&#x27;</span>) </span><br><span class="line">    img_tags = soup.find_all(<span class="string">&#x27;img&#x27;</span>,  &#123;<span class="string">&#x27;data-src&#x27;</span>: <span class="literal">True</span>&#125;)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 下载图片 </span></span><br><span class="line">    <span class="keyword">for</span> idx, img <span class="keyword">in</span> <span class="built_in">enumerate</span>(img_tags):</span><br><span class="line">        img_url = img[<span class="string">&#x27;data-src&#x27;</span>].replace(<span class="string">&#x27;&amp;amp;&#x27;</span>, <span class="string">&#x27;&amp;&#x27;</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            img_data = requests.get(img_url).content  </span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&#x27;<span class="subst">&#123;save_dir&#125;</span>/image_<span class="subst">&#123;idx+<span class="number">1</span>&#125;</span>.jpg&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(img_data) </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;已下载第 <span class="subst">&#123;idx+<span class="number">1</span>&#125;</span> 张图片&#x27;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;下载失败：<span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&#x27;</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    article_url = <span class="string">&#x27;https://mp.weixin.qq.com/s/xxxxxxxx&#x27;</span>   <span class="comment"># 替换为目标文章URL </span></span><br><span class="line">    download_images(article_url)</span><br></pre></td></tr></table></figure><hr><h2 id="三、进阶版实现（动态加载）"><a href="#三、进阶版实现（动态加载）" class="headerlink" title="三、进阶版实现（动态加载）"></a>三、进阶版实现（动态加载）</h2><h3 id="1-环境准备-1"><a href="#1-环境准备-1" class="headerlink" title="1. 环境准备"></a>1. 环境准备</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install selenium webdriver-manager </span><br></pre></td></tr></table></figure><h3 id="2-自动化爬取代码"><a href="#2-自动化爬取代码" class="headerlink" title="2. 自动化爬取代码"></a>2. 自动化爬取代码</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver </span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by  <span class="keyword">import</span> By </span><br><span class="line"><span class="keyword">import</span> time </span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dynamic_crawler</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="comment"># 配置无头浏览器 </span></span><br><span class="line">    options = webdriver.ChromeOptions()</span><br><span class="line">    options.add_argument(<span class="string">&#x27;--headless&#x27;</span>)   <span class="comment"># 隐藏浏览器窗口 </span></span><br><span class="line">    driver = webdriver.Chrome(options=options)</span><br><span class="line">    </span><br><span class="line">    driver.get(url) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 模拟滚动加载（解决动态加载问题）[[1]()]</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        driver.execute_script(<span class="string">&quot;window.scrollTo(0,  document.body.scrollHeight);&quot;</span>) </span><br><span class="line">        time.sleep(<span class="number">2</span>) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 提取图片链接 </span></span><br><span class="line">    images = driver.find_elements(By.XPATH,  <span class="string">&#x27;//img[@data-src]&#x27;</span>)</span><br><span class="line">    img_urls = [img.get_attribute(<span class="string">&#x27;data-src&#x27;</span>) <span class="keyword">for</span> img <span class="keyword">in</span> images]</span><br><span class="line">    </span><br><span class="line">    driver.quit() </span><br><span class="line">    <span class="keyword">return</span> img_urls</span><br></pre></td></tr></table></figure><hr><h2 id="四、关键功能扩展"><a href="#四、关键功能扩展" class="headerlink" title="四、关键功能扩展"></a>四、关键功能扩展</h2><h3 id="1-多文章批量爬取"><a href="#1-多文章批量爬取" class="headerlink" title="1. 多文章批量爬取"></a>1. 多文章批量爬取</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">article_list = [</span><br><span class="line">    <span class="string">&#x27;https://mp.weixin.qq.com/s/xxxx1&#x27;</span>, </span><br><span class="line">    <span class="string">&#x27;https://mp.weixin.qq.com/s/xxxx2&#x27;</span> </span><br><span class="line">]</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> article <span class="keyword">in</span> article_list:</span><br><span class="line">    urls = dynamic_crawler(article)</span><br><span class="line">    download_images(urls)</span><br></pre></td></tr></table></figure><h3 id="2-代理配置（防封禁）"><a href="#2-代理配置（防封禁）" class="headerlink" title="2. 代理配置（防封禁）"></a>2. 代理配置（防封禁）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;http://10.10.1.10:3128&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;http://10.10.1.10:1080&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">response = requests.get(url,  proxies=proxies)</span><br></pre></td></tr></table></figure><hr><h2 id="五、完整项目结构"><a href="#五、完整项目结构" class="headerlink" title="五、完整项目结构"></a>五、完整项目结构</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wx_image_crawler/</span><br><span class="line">├── crawler.py        # 主程序 </span><br><span class="line">├── config.yaml       # 代理/URL配置 </span><br><span class="line">├── requirements.txt  # 依赖库</span><br><span class="line">└── /wx_images       # 图片存储目录 </span><br></pre></td></tr></table></figure><blockquote><p>以上只是示例代码，并不能起到功能，仅用于学习。<br>项目源码下载：<a href="https://github.com/example/wx_crawler">Github仓库</a>  </p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>网课帮助</title>
      <link href="/2025/02/21/%E7%BD%91%E8%AF%BE%E5%B8%AE%E5%8A%A9/"/>
      <url>/2025/02/21/%E7%BD%91%E8%AF%BE%E5%B8%AE%E5%8A%A9/</url>
      
        <content type="html"><![CDATA[<h1 id="专业校园服务解决方案"><a href="#专业校园服务解决方案" class="headerlink" title="专业校园服务解决方案"></a>专业校园服务解决方案</h1><h2 id="🏆-核心业务体系"><a href="#🏆-核心业务体系" class="headerlink" title="🏆 核心业务体系"></a>🏆 核心业务体系</h2><h3 id="一、网课代刷服务"><a href="#一、网课代刷服务" class="headerlink" title="一、网课代刷服务"></a>一、网课代刷服务</h3><h2 id="✅-支持平台•-智慧职教-•-超星学习通-•-中国大学MOOC-•-学堂在线✅-服务优势▶︎-全自动完成视频-测试-考试（支持验证码识别）▶︎-异常状态智能修复（进度丢失-学时不足）▶︎-72小时急速托管（加急服务-30-费用）"><a href="#✅-支持平台•-智慧职教-•-超星学习通-•-中国大学MOOC-•-学堂在线✅-服务优势▶︎-全自动完成视频-测试-考试（支持验证码识别）▶︎-异常状态智能修复（进度丢失-学时不足）▶︎-72小时急速托管（加急服务-30-费用）" class="headerlink" title="✅ 支持平台• 智慧职教 • 超星学习通 • 中国大学MOOC • 学堂在线✅ 服务优势▶︎ 全自动完成视频&#x2F;测试&#x2F;考试（支持验证码识别）▶︎ 异常状态智能修复（进度丢失&#x2F;学时不足）▶︎ 72小时急速托管（加急服务+30%费用） "></a>✅ <strong>支持平台</strong><br>• 智慧职教 • 超星学习通 • 中国大学MOOC • 学堂在线<br>✅ <strong>服务优势</strong><br>▶︎ 全自动完成视频&#x2F;测试&#x2F;考试（支持验证码识别）<br>▶︎ 异常状态智能修复（进度丢失&#x2F;学时不足）<br>▶︎ 72小时急速托管（加急服务+30%费用） </h2><h3 id="二、智慧职教补签"><a href="#二、智慧职教补签" class="headerlink" title="二、智慧职教补签"></a>二、智慧职教补签</h3><h2 id="🛠-技术亮点1-突破平台补签次数限制2-自动修复异常学习记录3-支持批量操作（5门课程起订）-注：需提前3天预约系统日志覆盖周期"><a href="#🛠-技术亮点1-突破平台补签次数限制2-自动修复异常学习记录3-支持批量操作（5门课程起订）-注：需提前3天预约系统日志覆盖周期" class="headerlink" title="🛠 技术亮点1. 突破平台补签次数限制2. 自动修复异常学习记录3. 支持批量操作（5门课程起订）&gt; *注：需提前3天预约系统日志覆盖周期 "></a>🛠 <strong>技术亮点</strong><br><br>1. 突破平台补签次数限制<br>2. 自动修复异常学习记录<br>3. 支持批量操作（5门课程起订）<br><br>&gt; *注：需提前3天预约系统日志覆盖周期 </h2><h3 id="三、专利代理服务"><a href="#三、专利代理服务" class="headerlink" title="三、专利代理服务"></a>三、专利代理服务</h3><h2 id="🔬-代理类型对比-•-发明专利：授权率85-周期2-3年•-实用新型：授权率95-周期6-8月•-加急通道：周期缩短40"><a href="#🔬-代理类型对比-•-发明专利：授权率85-周期2-3年•-实用新型：授权率95-周期6-8月•-加急通道：周期缩短40" class="headerlink" title="🔬 代理类型对比  • 发明专利：授权率85% | 周期2-3年• 实用新型：授权率95% | 周期6-8月• 加急通道：周期缩短40% "></a>🔬 <strong>代理类型对比</strong><br><img src="https://example.com/patent-chart.png">  <!-- 替换为实际图表链接 --><br>• <strong>发明专利</strong>：授权率85% | 周期2-3年<br>• <strong>实用新型</strong>：授权率95% | 周期6-8月<br>• <strong>加急通道</strong>：周期缩短40% </h2><h2 id="💰-服务价目表（2025版）"><a href="#💰-服务价目表（2025版）" class="headerlink" title="💰 服务价目表（2025版）"></a>💰 服务价目表（2025版）</h2><table><thead><tr><th>服务类别</th><th>基础价</th><th>增值服务</th></tr></thead><tbody><tr><td>网课代刷</td><td>3元&#x2F;门</td><td>含考试+2元</td></tr><tr><td>专利代理</td><td>1600元起</td><td>加急费200元</td></tr><tr><td>紧急代跑</td><td>2元&#x2F;次</td><td>无</td></tr></tbody></table><hr><h2 id="🔒-安全保障体系"><a href="#🔒-安全保障体系" class="headerlink" title="🔒 安全保障体系"></a>🔒 安全保障体系</h2><ol><li><strong>数据加密</strong>：AES-256加密传输</li><li><strong>过程追溯</strong>：每小时进度反馈  </li><li><strong>赔付机制</strong>：服务失败100%退款</li></ol><hr><blockquote><p>完整价目表下载：<a href="https://example.com/price-list">点击此处</a>*  </p></blockquote><p>📞 <strong>联系通道</strong><br>QQ： 1904529192<br>请备注来意</p><!-- • 微信：`EDU_Service668`  • 邮箱：campus.pro@service.com   • 紧急热线：400-123-4567（24小时） -->]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>市集客户端-教程</title>
      <link href="/2025/02/19/%E5%B8%82%E9%9B%86%EF%BC%88%E6%9C%AC%E5%9C%B0%E7%89%88%EF%BC%89/"/>
      <url>/2025/02/19/%E5%B8%82%E9%9B%86%EF%BC%88%E6%9C%AC%E5%9C%B0%E7%89%88%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="📂-文件准备"><a href="#📂-文件准备" class="headerlink" title="📂 文件准备"></a>📂 文件准备</h2><h2 id="发货后您将获得两个必需文件：1-b站市集本地版-exe-主程序文件2-cookie-txt-账号凭证文件❗-重要提示：必须将两个文件放入同一文件夹，否则程序无法启动！"><a href="#发货后您将获得两个必需文件：1-b站市集本地版-exe-主程序文件2-cookie-txt-账号凭证文件❗-重要提示：必须将两个文件放入同一文件夹，否则程序无法启动！" class="headerlink" title="发货后您将获得两个必需文件：1. b站市集本地版.exe - 主程序文件2. cookie.txt  - 账号凭证文件❗ 重要提示：必须将两个文件放入同一文件夹，否则程序无法启动！ "></a>发货后您将获得两个<strong>必需文件</strong>：<br>1. <code>b站市集本地版.exe</code> - 主程序文件<br>2. <code>cookie.txt</code>  - 账号凭证文件<br><br>❗ <strong>重要提示</strong>：必须将两个文件放入<strong>同一文件夹</strong>，否则程序无法启动！ </h2><h2 id="🔑-获取Cookie完整流程"><a href="#🔑-获取Cookie完整流程" class="headerlink" title="🔑 获取Cookie完整流程"></a>🔑 获取Cookie完整流程</h2><h3 id="步骤一：登录B站账号"><a href="#步骤一：登录B站账号" class="headerlink" title="步骤一：登录B站账号"></a>步骤一：登录B站账号</h3><p>访问 <a href="https://mall.bilibili.com/neul-next/index.html?page=magic-market_index">B站魔力赏页面</a><br>👉 <strong>注意</strong>：若页面显示异常，请先完成<a href="https://passport.bilibili.com/login">B站账号登录</a>  </p><h3 id="步骤二：开启开发者工具"><a href="#步骤二：开启开发者工具" class="headerlink" title="步骤二：开启开发者工具"></a>步骤二：开启开发者工具</h3><ol><li>按 <code>F12</code> 打开浏览器开发者工具 </li><li>切换到 <strong>Network(网络)</strong> 标签 </li><li>刷新当前页面（快捷键 <code>Ctrl+R</code> &#x2F; <code>Cmd+R</code>）</li></ol><p><img src="/%E5%9B%BE%E7%89%87%E9%93%BE%E6%8E%A5%E5%BE%85%E8%A1%A5%E5%85%85" alt="开发者工具示意图"></p><h3 id="步骤三：提取关键Cookie"><a href="#步骤三：提取关键Cookie" class="headerlink" title="步骤三：提取关键Cookie"></a>步骤三：提取关键Cookie</h3><ol><li>在Network面板中找到任意<code>web?</code>开头的请求</li><li>点击请求后，在 <strong>Headers(标头)</strong> → <strong>Request Headers(请求头)</strong> 中找到<code>Cookie</code>字段</li><li>复制包含以下关键参数的完整Cookie字符串：<ul><li><code>SESSDATA</code>（用户会话凭证）</li><li><code>bili_jct</code>（跨站请求校验）</li><li><code>DedeUserID</code>（用户UID）</li></ul></li></ol><h3 id="步骤四：保存Cookie文件"><a href="#步骤四：保存Cookie文件" class="headerlink" title="步骤四：保存Cookie文件"></a>步骤四：保存Cookie文件</h3><ol><li>新建<code>cookie.txt</code> 文件（建议用记事本创建）</li><li><strong>完整粘贴</strong>复制的Cookie字符串 </li><li>保存时确保文件编码为 <strong>UTF-8</strong></li></ol><hr><h2 id="⚠️-常见问题说明"><a href="#⚠️-常见问题说明" class="headerlink" title="⚠️ 常见问题说明"></a>⚠️ 常见问题说明</h2><ol><li><p><strong>风控机制</strong>  </p><ul><li>新账号需持续使用3-5天解除风控限制</li><li>建议保持账号每日正常浏览行为</li></ul></li><li><p><strong>Cookie有效期</strong>  </p><ul><li>默认有效期为<strong>半年左右</strong>，到期需重新获取</li></ul></li><li><p><strong>多账号管理</strong>  </p><ul><li>不同账号需创建独立文件夹存放对应cookie.txt</li></ul></li></ol><hr><h2 id="🛠️-技术原理（扩展阅读）"><a href="#🛠️-技术原理（扩展阅读）" class="headerlink" title="🛠️ 技术原理（扩展阅读）"></a>🛠️ 技术原理（扩展阅读）</h2><h2 id="通过开发者工具获取的Cookie包含B站用于身份验证的加密参数：-wbi验证体系：涉及图片URL参数校验-buvid系列参数：设备指纹标识生成逻辑-uuid加密算法：基于时间戳的哈希生成机制"><a href="#通过开发者工具获取的Cookie包含B站用于身份验证的加密参数：-wbi验证体系：涉及图片URL参数校验-buvid系列参数：设备指纹标识生成逻辑-uuid加密算法：基于时间戳的哈希生成机制" class="headerlink" title="通过开发者工具获取的Cookie包含B站用于身份验证的加密参数：- wbi验证体系：涉及图片URL参数校验- buvid系列参数：设备指纹标识生成逻辑- _uuid加密算法：基于时间戳的哈希生成机制 "></a>通过开发者工具获取的Cookie包含B站用于身份验证的加密参数：<br>- <code>wbi验证体系</code>：涉及图片URL参数校验<br>- <code>buvid系列参数</code>：设备指纹标识生成逻辑<br>- <code>_uuid加密算法</code>：基于时间戳的哈希生成机制 </h2><blockquote><p>📌 提示：本文图片需替换为实际截图，建议参考<a href="%E3%80%90b%E7%AB%99cookie%E5%A6%82%E4%BD%95%E6%89%8B%E5%8A%A8%E8%8E%B7%E5%8F%96%EF%BC%88%E7%94%B5%E8%84%91%E7%AB%AF%EF%BC%89%E3%80%91https://www.bilibili.com/video/BV1BtpMeKETT?vd_source=faf06b414d98566625781bf4f3986333">B站教程视频</a><br>如果操作指南有矛盾的地方，一切以本文章为准</p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>凌  星</title>
      <link href="/2025/02/16/My-New-Post/"/>
      <url>/2025/02/16/My-New-Post/</url>
      
        <content type="html"><![CDATA[<p>星河如練夜無邊，凌渡星芒夢似煙</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
